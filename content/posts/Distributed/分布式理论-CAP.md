---
title: 分布式基础理论（CAP & BASE）
description: 简单分析分布基础理论，包括 CAP 理论、BASE 理论
toc: true
authors: 
    - WayneShen
tags: 
    - Distributed
    - Theory
categories: 
    - Distributed
series: []
date: '2021-03-06T16:21:+08:00'
lastmod: '2021-03-06T16:21:20+08:00'
featuredImage: ''
draft: false
---

</br>

简单分析分布基础理论，包括 CAP 理论、BASE 理论

<!--more-->

## CAP 理论

+ **Consistency**：一致性。**在分布式系统中的所有数据备份，在同一时刻是否同样的值**。也就是说，所有节点访问同一份最新的数据副本。写操作之后的读操作，必须返回该值。client 写到服务器 G1，在从服务器 G2 读时，必须也要读到一致的数据。即 G1 需要与 G2 通信，将数据同步给 G2。

+ **Availability**：可用性。**在集群中一部分节点故障后，集群整体是否还能响应客户端的读写请求**。对数据更新具备高可用性。只要收到用户的请求，服务器就必须给出回应。

+ **Partition tolerance**：分区容忍性。**网络是不可靠的**，多机房异地部署导致服务通信存在问题，一旦出现多个集群之间断连或其中一个分区瘫痪时，系统是否可以正常工作，所以需要系统能够容忍这种情况发生。一般方案，如果网络发生分区，或失去一致性（因为允许分别更新分区两边），或失去可用性（因为检测到错误，调整系统，直到分区消失）。
以实际效果而言，分区相当于对通信的时限要求。系统如果不能在时限内达成数据一致性，就意味着发生了分区的情况，必须就当前操作在 C 和 A 之间做出选择。


### C 和 A 之间的矛盾

一致性和可用性不可同时成立，通信可能失败（需要进行分区容错）。

+ 若保证 G2 的一致性，那么 G1 必须在写操作时，锁定 G2 的读操作和写操作。只有数据同步后，才能重新开放读写。锁定期间，G2 不能读写，无可用性。

+ 若保证 G2 的可用性，那么势必不能锁定 G2，所以一致性不成立。

综上所述，G2 无法同时做到一致性和可用性。系统设计时只能选择一个目标，若追求一致性，那么无法保证所有节点的可用性；若追求所有节点的可用性，那就没法做到一致性。

### 三者权衡

流行的说法是，因为分布式系统分区无法避免，所以 P 总是需要保证成立，所以需要再 C 和 A 之间做取舍，即只能满足 CP 或 AP。

其实这种说法并不准确，首先分区的情况很少出现，其实大多数情况下时可以同时满足 C 和 A 的。分区容忍性意味着，需要开发一个应对策略，当分区时，丢弃一致性或可用性。这时真正从 CAP 中学到的，当有个会丢消息的网络，你就不能同时拥有可用性和一致性。

所以，其实分区容忍性是对可用性的衡量。那为什么会导致分区？第一可能是网络故障，比如交换机坏了，线路断了；第二可能是机器故障，无论是软件或硬件的故障。

比如在异步网络中，消息处理没有在指定时间完成，无法区分是机器故障还是消息丢失了。此时那台故障机器与其余机器便发生了分区。如果错误发生在一组机器，那该组机器与其他组的机器也就发生了分区。对于分布式系统而言，没有收到消息与网络没有投递消息其实是等价的。所以当足够多的机器故障时，保持可用性或一致性是不可能的，不是因为写到了不同的分区，而是机器数量达不到的规定的数目（quorum机制），可能导致最近的写没法读出来。

之所以说分区容忍（P）是必选的，是因为我们潜意识里就认为网络是不可靠的，机器故障是不可预料，无法控制的。需要为其发生做好准备。

但将 P 定义为“允许分区保持可用”其实是存在误导性的，所以私以为，需要保证分区容忍（P），是因为如果分布式系统想要搭建一个永不发生相关故障的网络上，是不可能的。所以需要在当失败事件来临时，可以牺牲一些可用性或一致性。比如当分区产生时，自动或及时做出预备策略来处理。首先要能感知分区的产生，其次限制某些操作，然后就是启动恢复过程，恢复数据一致性，补偿分区发生期间的错误。

当机器扩展到成百上千的规模时，一旦发生错误，维持一致性变得非常昂贵。如果考虑到吞吐量和延迟时，维护一致性比维护可用性代价更高。Zookeeper是顺序一致的，因为集群规模够小，把数据写入法定多数的机器代价相对较小。HDFS也选择了一致性，如果倒霉，三个数据节点故障就导致文件块不可用。两个系统都设计为，能在普通的网络环境运行，当分区和失败发生时，他们可能变得不可用，在一致性和可用性间选择了一致性。对分布式系统来说，这种选择是不可避免的。

### CAP 总结

+ 只有单点结构才能同时满足 CA

+ 何时满足 CP。对于一致性要求较高的场景，比如 zookeeper，在服务节点间服务同步时，服务对外不可用。

+ 何时满足 AP。对可用性要求较高的场景。例如 Eureka，必须保证注册中心随时可用，不然拉取不到服务就可能出问题。可能服务挂了都不知道。


## BASE 理论

+ Basically Available：基本可用

+ Soft state：软状态

+ Eventually consistent：最终一致性

### 理论分析

BASE理论，基于 CAP 定律逐步演化而来。其核心思想是**即使无法做到强一致性**，但每个应用都可以根据自身业务特点，采用适当的方式来**使系统达到最终一致性**。


#### 基本可用

当系统出现不可预知故障时，相比较正常系统而言，基本还是可以继续使用。

+ 损失响应时间，比如本来正常 RT 为 500ms，最后变成 2s。

+ 损失功能，比如用户本可以正常可以下单，最终被引导到了降级的页面。

#### 软状态

原子性保证多个节点的副本数据都是一致的，这种属于硬状态；

而软状态是指，**允许系统中的数据存在中间状态，这种中间状态并不会影响系统整体的可用性**。也就是说，允许系统在不同节点的数据副本存在延时。


#### 最终一致性

软状态虽然允许存在，但**需要保证在时间期限后所有副本数据的一致性，这就是数据的最终一致性**。

时间延迟期限取决于网络延迟、系统负载、数据复制方案等设计因素影响。

### BASE 总结

BASE理论面向建立大型高可用、可扩展的分布式系统。允许牺牲强制一致性来获得可用性，即数据在一段时间内不一致，但最终达到一致性状态。

需要结合实际业务来设计使用。
