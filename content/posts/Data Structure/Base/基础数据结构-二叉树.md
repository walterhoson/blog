---
title: 基础数据结构-二叉树
description: 树（Tree）是由 n（n>0）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。
toc: true
authors: 
    - WayneShen
tags: 
    - Data Structure
    - Notes
categories: 
    - Data Structure
series: [Data Structure]
date: '2021-06-02T01:20:08+08:00'
lastmod: '2021-06-02T01:30:08+08:00'
featuredImage: ''
draft: false
---

</br>

树（Tree）是由 n（n > 0）个有限节点组成一个具有层次关系的集合。把它叫做“树”是因为它看起来像一棵倒挂的树，也就是说它是根朝上，而叶朝下的。

<!--more-->

## 树

树中的每个元素叫**节点**，用来连线相邻节点之间的关系，叫做**父子关系**。

树的三个概念：高度（Height）、深度（Depth）、层（Level）。

+ 节点的高度：节点到叶子节点的最长路径（边数）

+ 节点的深度：根节点到这个节点所经历的边的个数

+ 节点的层数：节点的深度 + 1

+ 树的高度：根节点的高度

## 二叉树

二叉树（Binary Tree）中，每个节点最多两个字节点，分别为左子节点和右子节点。

满二叉树：叶子节点全在最底层，除了叶子节点外，每个节点都有左右两个子节点的二叉树。

完全二叉树：叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层其他层的节点个数都达到了最大的二叉树。堆就属于完全二叉树（常用数组存储）。

### 存储二叉树

**基于指针或引用的二叉链式存储法**

每个节点有三个字段，其中一个存储数据，另外两个是指向左右字节点的指针。只要拎住根节点，就可以通过左右字节点的指针把整棵树串起来了。

比较简单，大部分二叉树代码由这种结构实现。

**基于数组的顺序存储法**

把根节点存储在下标 ``i = 1`` 的位置，左子节点存在 ``2 * i = 2`` 的位置，右子节点存在 ``2 * i + 1 = 3`` 的位置，并以此类推。

反过来说，下标为 i / 2 的位置存储的就是当前节点的父节点。这种方式只要知道根节点存储的位置（一般方便计算都将根节点存储在下标为 1 的位置），就可以将整棵树串起来。

完全二叉树仅仅浪费下标为 0 的位置，如果是非完全二叉树，会浪费比较多的位置。

因为不需要像链表一样存储左右节点的指针，所以较为节省内存。而完全二叉树最后一层要求都要靠左也是出于这个原因（为了省内存）。

### 遍历

所谓前中后序遍历，主要就是节点本身的打印顺序相比较于它的左右子节点打印的顺序。

#### 遍历方式

+ 前序遍历：对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。

+ 中序遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。

+ 后续遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。

#### 图例

![image](../../../assets/基础数据结构-二叉树/image-20201226142430738.png)

通过递归实现遍历的递推公式

```c
//前序遍历的递推公式：
preorder(r) = print r -> pre0rder(r -> left) -> pre0rder(r -> right)
//中序遍历的递推公式：
in0rder(r) = in0rder(r -> left) -> print r -> inorder(r -> right)
//后序遍历的递推公式：
postorder(r) = postorder(r -> left) -> postorder(r -> right) -> print r
```

伪代码

```c
 void preorder(Node* root) {
   if (root == null) return;
   print root //此处为伪代码，表示打印 root 节点
   pre0rder(root->left);
   preorder(root->right);
 }

 void inorder(Node* root)
   if (root ==null) return;
   inorder( root->left);
   print root //此处为伪代码，表示打印 root 节点
   inOrder (root->right);
 }

 void postorder(Nodex root) {
   if (root == null) return;
   postOrder(root->left);
   postOrder( root->right);
   print root //此处为伪代码，表示打印 root 节点
 }
```

每个节点最多会被访问两次，所以遍历操作的时间复杂度，跟节点的个数 n 成正比，二叉树遍历的时间复杂度是 O(n)。

## 二叉查找树

二叉查找树（Binary Search Tree）也叫二叉搜索树或二叉排序树。为实现快速查找而生，同时还支持快速插入、删除一个数据。

二叉查找树要求，**在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值**。

### 查找

先取根节点，等于则直接返回，如果要查找的数据比根节点的值小，则到左子树中递归查找，否则在右子树中递归查找。

```java
public class BinarySearchTree {
  private Node tree;
  public Node find(int data) {
    Node p = tree;
    while (p != null) {
      if (data < p.data) p = p.left;
      else if (data > p.data) p = p.right;
      else return p;
    }
    return null;
  }
  public static class Node {
    private int data;
    private Node left;
    private Node right;
    public Node(int data) {
      this.data = data;
    } 
  }
}
```

### 插入

与查找类似，新插入的数据一般都是在叶子节点上，所以只需要从根节点开始，依次比较要插入的数据与节点的大小关系。

若要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。

同理，若要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。

```java
public void insert(int data) {
  if (tree == null) {
    tree = new Node(data);
    return;
  }
  Node p = tree;
  while (p != null) {
 		if (data > p.data) {
      if (p.right == null) {
  			p.right = new Node(data);
  			return;
      }
      p = p.right;
    } else { // data < p.data
      if (p.left == null) {
  			p.left = new Node(data);
  			return;
      }
      p = p.left;
    }
 }
}
```

### 删除

相对复杂，针对要删除节点的子节点个数的不同，需要分三种情况考虑

+ 若要删除的节点没有子节点，只需要将父节点中，指向要删除节点的指针置为 null。

+ 若要删除的节点只有一个子节点（左 / 右），只需要更新父节点中指向要删除的节点的指针，让它指向要删除节点的子节点。

+ 若要删除的节点有两个子节点，相对较复杂。需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以可以应用上面两条规则来删除这个最小节点。

```java
public void delete(int data) {
  Node p = tree; // p 指向要删除的节点，初始化指向根节点
  Node pp = null; // ppi 录的是 p 的父节点
  while (p!= null && p.data != data) {
    pp =p;
    if (data > p.data) p =p.right;
    else p = p.left;
  }
  if (p == null) return; //没有找到
  //要删除的节点有两个子节点
  if (p. left != null && p.right != null) { //查找右子树中最小节点
    Node minP = p.right;
    Node minPP = p; // minPP 表示 minP 的父节点
    while (minp. left != null) {
      minPP = minP;
      minP = minP. left;
    }
    p.data = minP.data; //将 minP 的数据替换到 p 中 p=minP; //下面就变成了删除 minP 了
    pp = minPP;
    //删除节点是叶子节点或者仅有一个子节点
    Node child; // p 的子节点
    if (p. left != null) {
      child =p.left; 
    } else if (p.right != null) {
      child =p.right;
    } else {
      child = null;
    } 
    if (pp =s null) {
      tree = child; //删除的是根节点 
    } else if (pp.left ==p) {
      pp. left = child; 
    } else {
    	pp.right = child;
    }
  }
}
```

此外，还可以只是将要删除的节点标记为“已删除”，并不是真正删除节点。如此操作比较浪费空间，但操作相对简单。

### 其他操作

二叉查找树，还支持快速的查找最大和最小节点、前驱节点和后继节点。

此外，二叉查找树还有个重要的特性，**中序遍历二叉查找树，可以输出要有序的数据序列，时间复杂度为 O(n)，非常高效**。

所以二叉查找树也叫二叉排序树。

### 使其支持重复数据

+ 方案一：每个节点不仅仅会存储一个数据，同时可以通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。

+ 方案二：不好理解，但更加优雅。每个节点仍然只存储一个数据。在查找插入位置的过程中，若碰到一个节点的值，与要插入数据的值相同，就将这个要插入的数据放到该节点的右子树，即把这个新插入的数据当作大于该节点的值处理；当要查找数据时，遇到值相同的节点，并不停止查找，而是继续在右子树中查找，直到遇到叶子节点才停止。如此就可以把键值等于要查找的所有节点都找出来；当要删除时，也需要查找到每个要删除的节点，然后再按照之前的删除操作的方法，依次删除。

### 时间复杂度分析

若左右子树极度不平衡，就可能退化为链表，查找时间复杂度为 O(n)。

最理想的情况下，二叉查找树是一棵完全二叉树（或满二叉树），此时时间复杂度与树的高度成正比，O(height)。

完全二叉树，第 k 层包含的节点个数为 2<sup>k-1</sup>。假设最大层数是 L，由于

n >= 1+2+4+8+...+ (2<sup>L-2</sup>+1)

n <= 1+2+4+8+...+ 2<sup>L-2</sup> + 2<sup>L-1</sup>

借助等比数列求和公式，L 的取值范围是 [ log<sub>2</sub>(n+1)， log<sub>2</sub>n+1 ]，完全二叉树的层数小于等于 log<sub>2</sub>n + 1，也就是高度小于等于 log<sub>2</sub>n 。

使用平衡二叉查找树，高度接近 logn，此时插入、删除、查找的时间复杂度比较稳定，为 O(logn)

## 平衡二叉查找树

**平衡二叉树**的严格定义是这样的：**二叉树中任意一个节点的左右子树的高度相差不能大于 1**。

从这个定义来看，完全二叉树、满二叉树其实都是平衡二叉树。非完全二叉树，也有可能是平衡二叉树。

平衡二叉查找树不仅仅满足平衡二叉树定义，同时满足二叉查找树的特点。最先被发明的平衡二叉查找树是 AVL 树，它严格符合平衡二叉查找树定义，即任何节点的左右子树高度相差不超过 1，是一种高度平衡的二叉查找树。

但很多平衡二叉查找树其实并没有严格符合上面的定义（树中任意一个节点的左右子树的高度相差不能大于 1）, 比如红黑树，它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍。

所以，平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。

## 红黑树

Red-Black Tree，简称 R-B Tree。它是不严格的平衡二叉查找树，只是做到了近似的平衡。

红黑树中的节点，一类被标记为黑色，一类被标记为红色。此外还需要满足以下：

+ 根节点是黑色的；

+ 每个叶子节点都是黑色的空节点 (NIL) ，也就是说，叶子节点不存储数据；

+ 任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；

+ 每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

所以将红色节点拿掉（其子节点与其父节点直接相连），二叉树变成了四叉树 ，由于红黑树中从任意节点到可达的叶子节点的每个路径包含相同数目的黑色节点。此时从四叉树中取出某些节点，放到叶节点位置，四叉树就变成了完全二叉树。所以，仅包含黑色节点的四叉树的高度，比包含相同节点个数的完全二叉树的高度还要小。

完全二叉树的高度近似 log<sub>2</sub>n，这里的四叉“黑树”的高度要低于完全二叉树，所以去掉红色节点的“黑树”的高度也不会超过 log<sub>2</sub>n。

由于红黑节点相隔，包含最多黑色节点的路径不会超过 log<sub>2</sub>n ，所以加上红色节点后，最长路径不会超过 2log<sub>2</sub>，也就是说红黑树的高度近似 2log<sub>2</sub>n。

所以，红黑树的高度只比高度平衡的 AVL 树的高度（log<sub>2</sub>n）仅仅大了一倍，在性能上，下降得并不多。这样推导出来的结果不够精确，实际上红黑树的性能更好。

### 实现逻辑

两个重要的操作，左旋、右旋

左旋全称是，围绕某个节点的左旋，同样右旋就是，围绕某个节点右旋。

![image](../../../assets/基础数据结构-二叉树/e7b54cbaf8adac5f7d6289f00edd6be6.png)

### 插入操作的平衡性调整

红黑树规定，插入的节点必须是红色的。而且，二叉查找树中新插入的节点都是放在叶子节点上。所以，关于插入操作的平衡调整，有两种特殊情况，但都非常好处理：

+ 若插入节点的父节点是黑色的，那无需调整，它仍然满足红黑树的定义。

+ 若插入的节点是根节点，那直接改变它的颜色，把它变成黑色就可以了。

除此之外，其他情况都会违背红黑树的定义，于是就要进行调整，调整的过程包含两种基础操作：**左右旋转**和**改变颜色**。

红黑树的平衡调整过程是一个迭代的过程，把正在处理的节点叫作关注节点，关注节点会随着不停地迭代处理，而不断发生变化；最开始的关注节点就是新插入的节点。

新节点插入后，若红黑树的平衡被打破，那一般会有下面三种情况。只需要根据每种情况的特点，不停地调整，就可以让红黑树继续符合定义，也就是继续保持平衡。

下面依次来看每种情况的调整过程。为了简化描述，把父节点的兄弟节点叫作叔节点，父节点的父节点叫作祖父节点。

**CASE 1:** 若关注节点是 a，它的叔叔节点 d 是红色，就依次执行下面的操作：

+ 将关注节点 a 的父节点 b、叔节点 d 的颜色都设置成黑色；

+ 将关注节点 a 的祖父节点 c 的颜色设置成红色；

+ 关注节点变成 a 的祖父节点 c;

+ 跳到 CASE 2 或 CASE 3。

![image](../../../assets/基础数据结构-二叉树/case-1.png)

**CASE 2:** 若关注节点是 a，它的叔节点 d 是黑色，关注节点 a 是其父节点 b 的右子节点，就依次执行下面的操作：

+ 关注节点变成节点 a 的父节点 b;

+ 围绕新的关注节点 b 左旋；

+ 跳到 CASE 3.

![image](../../../assets/基础数据结构-二叉树/case-2.png)

**CASE 3:** 若关注节点是 a，它的叔节点 d 是黑色，关注节点 a 是其父节点 b 的左子节点，就依次执行下面的操作：

+ 围绕关注节点 a 的祖父节点 c 右旋；

+ 将关注节点 a 的父节点 b、兄弟节点 c 的颜色互换；

+ 调整结束。

![image](../../../assets/基础数据结构-二叉树/case-3.png)

### 删除操作的平衡性调整

删除操作的平衡调整相对插入较难难。不过原理都是类似的，依旧只需要根据关注节点与周围节点的排布特点，按照一定的规则去调整。调整分为两步：

1. 针对删除节点初步调整。为了只是保证整棵红黑树在一个节点删除后，仍然满足最后一条定义的要求，即每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

2. 针对关注节点进行二次调整，让它满足红黑树的第三条定义，即不存在相邻的两个红色节点。

#### 初步调整

这里需要注意一下，红黑树的定义中“只包含红色节点和黑色节点”，经过初步调整之后，为了保证满足红黑树定义的最后一条要求，有些节点会被标记成两种颜色，“红一黑”或“黑-黑”。

如果一个节点被标记为了“黑-黑”，那在计算黑色节点个数时，要算成两个黑色节点。

若一个节点既可以是红色，也可以是黑色，图中用一半红色一半黑色来表示。若一个节点是“红-黑”或“黑一黑”，图中用左上角的一个小黑点来表示额外的黑色。

**CASE 1:** 若要删除的节点是 a，它只有一个子节点 b，那就依次进行下面的操作：

+ 删除节点 a，并且把节点 b 替换到节点 a 的位置，这一部分操作跟普通的二叉查找树的删除操作一样；

+ 节点 a 只能是黑色，节点 b 也只能是红色，其他情况均不符合红黑树的定义。这种情况下，把节点 b 改为黑色；

+ 调整结束，不需要进行二次调整。

![image](../../../assets/基础数据结构-二叉树/delete-1-case-1.png)

**CASE 2:** 若要删除的节点 a 有两个非空子节点，并且它的后继节点就是节点 a 的右子节点 c。就依次进行下面的操作：

+ 若节点 a 的后继节点就是右子节点 c, 那右子节点 c 肯定没有左子树。我们把节点 a 删除，并且将节点 c 替换到节点 a 的位置。这一部分操作跟普通的二叉查找树的删除操作无异

+ 然后把节点 c 的颜色设置为跟节点 a 相同的颜色；

+ 若节点 c 是黑色，为了不违反红黑树的最后一条定义，给节点 c 的右子节点 d 多加一个黑色，此时节点 d 就成了"红-黑”或“黑-黑”;

+ 此时，关注节点变成了节点 d, 第二步的调整操作就会针对关注节点来做。

![image](../../../assets/基础数据结构-二叉树/delete-1-case-2.png)

**CASE 3:** 若要删除的是节点 a, 它有两个非空子节点，并节点 a 的后继节点不是右子节点，就依次进行下面的操作：

+ 找到后继节点 d, 并将它删除，删除后继节点 d 的过程参照 CASE 1；

+ 将节点 a 替换成后继节点 d；

+ 把节点 d 的颜色设置为跟节点 a 相同的颜色；

+ 若节点 d 是黑色，为了不违反红黑树的最后一条定义，给节点 d 的右子节点 c 多加-个黑色，此时节点 c 就成了“红-黑”或者"黑一黑"；

+ 此时，关注节点变成了节点 c, 第二步的调整操作就会针对关注节点来做。

![image](../../../assets/基础数据结构-二叉树/delete-1-case-3.png)

#### 二次调整

经过初步调整之后，关注节点变成了“红-黑”或“黑-黑”节点。针对这个关注节点，再分四种情况来进行二次调整。二次调整是为了让红黑树中不存在相邻的红色节点。

**CASE 1:** 若关注节点是 a，它的兄弟节点 c 是红色的，就依次进行下面的操作：

+ 围绕关注节点 a 的父节点 b 左旋；

+ 关注节点 a 的父节点 b 和祖父节点 c 交换颜色；

+ 关注节点不变；

+ 继续从四种情况中选择适合的规则来调整。

![image](../../../assets/基础数据结构-二叉树/delete-2-case-1.png)

**CASE 2:** 若关注节点是 a, 它的兄弟节点 c 是黑色的，并且节点 c 的左右子节点 d、e 都是黑色的，就依次进行下面的操作：

+ 将关注节点 a 的兄弟节点 c 的颜色变成红色；

+ 从关注节点 a 中去掉一个黑色，此时节点 a 就是单纯的红色或者黑色；

+ 给关注节点 a 的父节点 b 添加一个黑色，此时节点 b 就变成了“红-黑”或“黑黑";

+ 关注节点从 a 变成其父节点 b

+ 继续从四种情况中选择符合的规则来调整。

![image](../../../assets/基础数据结构-二叉树/delete-2-case-2.png)

**CASE 3:** 若关注节点是 a, 它的兄弟节点 c 是黑色，c 的左子节点 d 是红色，c 的右子节点 e 是黑色，就依次进行下面的操作：

+ 围绕关注节点 a 的兄弟节点 c 右旋；

+ 节点 c 和节点 d 交换颜色；

+ 关注节点不变；

+ 跳转到 CASE 4, 继续调整。

![image](../../../assets/基础数据结构-二叉树/delete-2-case-3.png)

**CASE 4:** 若关注节点 a 的兄弟节点 c 是黑色的，并且 c 的右子节点是红色的，就依次进行下面的操作

+ 围绕关注节点 a 的父节点 b 左旋；

+ 将关注节点 a 的兄弟节点 c 的颜色，跟关注节点 a 的父节点 b 设置成相同的颜色；

+ 将关注节点 a 的父节点 b 的颜色设置为黑色；

+ 从关注节点 a 中去掉一个黑色，节点 a 就变成了单纯的红色或黑色；

+ 将关注节点 a 的叔叔节点 e 设置为黑色；

+ 调整结束。

![image](../../../assets/基础数据结构-二叉树/delete-2-case-4.png)

**补充**

AVL 树是一种高度平衡的二叉树，所以查找的效率非常高，但是有利有弊，AVL 树为了维持高度的平衡，要付出更多的代价。每次插入、删除都要做调整，比较复杂、耗时。

所以，对于有频繁的插入、删除操作的数据集合，使用 AVL 树的代价就有点高了。

## 递归树

通常借助递归树来分析递归算法的时间复杂度。

递归的思想就是大问题分解为小问题来求解，然后小问题分解为小小问题，一层层分解，直到问题的数据规模被分解得足够小，不用继续递归分解为止。将一层层分解得过程画成图，就是一棵递归树。
