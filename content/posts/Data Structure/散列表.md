---
title: 散列表
description: 散列表（Hash Table）也叫 Hash 表。底层基于数组，利用其支持按照下标随机访问数据的特性。时间复杂度为 O(1)。通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。按照键值查询元素时，用同样的散列函数，将键值转化为数组下标，从对应的数组下标的位置获取数据。
toc: true
authors: 
    - WayneShen
tags: 
    - Data Structure
    - Notes
categories: 
    - Data Structure
series: [Data Structure]
date: '2021-06-02T01:10:+08:00'
lastmod: '2021-06-02T01:10:08+08:00'
featuredImage: ''
draft: false
---

</br>

散列表（Hash Table）也叫 Hash 表。底层基于数组，利用其支持按照下标随机访问数据的特性。时间复杂度为 O(1)。

通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。按照键值查询元素时，用同样的散列函数，将键值转化为数组下标，从对应的数组下标的位置获取数据。

<!--more-->

## 散列函数

`hash(key)`，其中 key 表示元素的键值，`hash(key)` 的值表示经过散列函数计算得到的散列的值。

散列函数设计的三点基本要求

1. 散列函数计算得到的散列值时一个非负整数

2. 若 `key1 == key2`，那 `hash(key1) == hash(key2)`

3. 若 `key1 != key2`，那 `hash(key1) != hash(key2)`

### 散列冲突

再好的散列函数也无法避免散列冲突。解决方法有，开放寻址法（open addressing）、链表法（chaining）。

#### 开放寻址法

核心思想是，若遇到散列冲突，就重新探测一个空闲位置，将其**插入**。可以通过**线性探测**（Linear Probing）的方式。

即从当前位置开始往后找，看是否有空闲位置，直到找到为止。ThreadLocalMap 采用此种方法。

而**查找**的过程也类似，通过散列函数找出元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素，若相等，则表示已找到，否则顺序往后依次查找。如果遍历到数组中的空闲位置还没找到，说明该元素不在散列表中。

**删除**时不能单纯的把要删除的元素设置为空，因为如果直接删除，则可能影响以上查找的逻辑，导致查找认定为元素不存在。所以应该将删除的元素特殊标记为 deleted，在线性探测查找时，遇到 deleted 标记的空间，并不是停下来，而是继续往下探测。

**存在问题**

散列表插入的数据越多，冲突的可能性就越大，空闲位置就越少，线性探测的时间就越长。极端情况可能需要探测整个散列表，所以最坏情况下时间复杂度为 O(n)，删除也是同理。

除了通过线性探测外，还有两个经典的探测方法，二次探测（Quadratic probing）和双重散列（Double hashing）。

**二次探测**

和线性探测相似，但二次探测的步长不是 1，而是二次方，hash(key)+0，hash(key)+1<sup>2</sup>，hash(key)+2<sup>2</sup>,......

**双重散列**

不仅要使用一个散列函数，而是使用一组散列函数 hash1(key)，hash2(key)，hash3(key).......

先使用第一个散列函数，冲突则再使用第二个，依次类推，知道找到空闲的存储空间。

不管使用哪种，散列表中空闲的位置不对，必然会导致冲突的概率提高。所以，需要保证散列表中有一定比例的空闲槽位，用装载因子（load factor）表示空位的多少。

**装载因子 = 填入表中的元素个数 / 散列表的长度**。装载因子越大，说明空闲位置越少，冲突越多，散列表性能会下降。

数据量小、装载因子小时，适合采用开放寻址法，可以有效利用 CPU 缓存加快查询速度。

#### 链表法

比开放寻址法简单，每个桶（bucket）或槽（slot）会对应一条链表，所有散列值相同的元素都放到同一个槽位对应的链表中。HashMap 采用此种方法。

插入时，通过散列函数计算对应的散列槽位，将其插入对应链表中，插入时间复杂度 O(1)；

查找和删除元素一个元素时，同样通过散列函数计算出对应的槽位，遍历链表进行查找和删除。时间复杂度为 O(k)，与链表的长度 k 成正比，理论上 `k = n/m`，n 是散列中数据的个数，m 表示散列表中槽的个数。

链表法比起开放寻址法，对装载因子的容忍度更高。只要散列函数的值随机均匀，即便装载因子变为 10，也就是链表的长度变长了，查找效率有所下降，但还是比顺序查找要快很多。

链表中结点是零散分布在内存中，不是连续的，所以对 CPU 缓存不友好，也对执行效率有一定影响。

若是比较大的对象，链表中存储指针内存消耗就可以忽略了。

实际上如果将链表改造为其他高效的动态数据结构，比如跳表、红黑树，那么在出现散列冲突极端情况下，所有数据都散列到一个桶里，最终退化的散列表的查询时间也不过是 O(logn)。也有效避免了散列碰撞攻击。

所以基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，比开放寻址法更加灵活，支持更多的优化策略，比如使用红黑树代替链表。

### 如何设计散列函数

散列函数不能设计的过于复杂，太过复杂必然会消耗计算时间，间接影响性能。

散列函数生成的值要尽可能随机并且均匀分布，以避免或最小化散列冲突，即使冲突每个槽里的数据也要比较平均。

#### 装载因子设置

装载因子越大，说明空闲位置越少，冲突概率越大。不仅插入数据时要多次寻址或拉很长的链，查找也会变慢。

所以当装载因子过大时，可以进行动态扩容，重新申请一个更大的散列表，将数据 rehash 后，搬移到新散列表中，同时降低装载因子。

插入数据若不需要扩容则最好时间复杂度为 O(1)，最坏情况需要扩容，重新申请内存空间，重新计算哈希位置，并搬移数据，时间复杂度为 O(n)，用摊还分析法，均摊情况，时间复杂度接近最好情况，O(1)。

此时这个装载因子的阈值，需要权衡时间、空间复杂度，若内存不紧张，对执行效率要求高，可以降低负载因子的阈值，相反如果内存空间紧张，对执行效率要求不高，可以增大负载因子的值，甚至可以大于 1。

#### 避免低效扩容

若当前散列表已经很大，直接扩容为两倍会比较耗时。所以，可以将扩容操作穿插在插入操作过程中，分批完成。

当装载因子触达阈值之后，只申请新空间，并不将老数据搬移到新的散列表中。

当有新数据插入时，将新插入的数据插入新散列表中，并从老的散列表中哪一个数据放入新的散列表。

重复多次，将老散列表一步步搬移到新表中。查询数据则可以先从新的找，找不到再去老的里面找。此时时间复杂度为 O(1)。

#### 工业级散列表

从 Java 中的 HashMap 来分析。

1. **初始大小**。HashMap 默认 16，若事先知道数据量，可修改默认大小，减少动态扩容次数，提高性能。

2. **装载因子和动态扩容**。HashMap 默认装载因子 0.75，元素个数超过 0.75*capacity（散列容量），则启动扩容，扩为原来的两倍。

3. **散列冲突的解决方法**。JDK1.8 中，HashMap 中链表树化的阈值为 8，超过则链表转化为红黑树，利用了红黑树的快速增删改查，个数小于 8 时，又转为链表，因为数据量少的情况下，红黑树有维护平衡的代价，优势不明显。

4. **散列函数**。简单并分布均匀。

## 散列表使用场景

### LRU 缓存淘汰算法

借助散列表可以将 LRU 缓存淘汰算法时间复杂度降为 O(1)。

#### 链表实现 LRU

**需要维护一个按照访问时间从大到小有序排列的链表结构**。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据时，就直接将链表头部的结点删除。

当要缓存某个数据时，先在链表中查找这个数据。若没找到，则直接将数据放到链表的尾部；若找到了，就把它移动到链表的尾部。

因为查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间复杂很高，是 O(n)。

#### 结合散列表

使用双向列表存储数据，链表中的每个结点除了数据（data）、前驱指针（prev）、后继指针（next）外，还新增一个特殊字段 hnext。

有两个链，一个是双向列表，另一个链是散列表中的拉链。前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。

**查找数据**

由于散列表时间复杂度接近 O(1)，通过散列表就能很快找到数据，找到后并将它移动到双向链表尾部。

**删除数据**

借助散列表，以 O(1) 的时间复杂度找到数据并删除，利用双向链表特性，以 O(1) 的时间复杂度获取删除结点的前驱结点。

**添加数据**

首先查看数据是否已经在缓存中，在则需要将其移动到双向链表尾部，不在则看缓存是否已满，满了则将双向链表头部结点删除，然后将数据放入链表尾部，不满则直接放入链表尾部。

### LinkedHashMap

Java 中的 LinkedHashMap 是通过双向链表和散列表这两种数据结构组合实现的。

LinkedHashMap 中的"Linked"实际上是指的是双向链表，并非指用链表法解决散列冲突。

## 参考资料

《数据结构与算法之美》
