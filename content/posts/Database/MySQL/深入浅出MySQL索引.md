---
title: 深入浅出 MySQL 索引
description: 分析 MySQL 中索引数据模型，以及索引的维护。
toc: true
authors: 
    - WayneShen
tags: 
    - MySQL
    - Notes
categories: 
    - DataBase
series: []
date: '2020-08-28T21:50:+08:00'
lastmod: '2020-08-28T21:50:20+08:00'
draft: false
---

</br>

分析 MySQL 中索引数据模型，以及索引的维护。

<!--more-->

## 索引模型

### 常见索引数据结构

+ 哈希表
  + 不是有序的，哈希索引做区间查询的速度很慢。
  + **无法利用索引进行排序**，也无法实现多列联合索引的最左匹配原则。
  + 哈希表这种结构**适用于只有等值查询的场景**，比如 Memcached 以及其他一些 NoSQL 引擎。
  + 还会存在 **hash 碰撞**的问题。

+ 有序数组
  + 有序数组在**等值查询**和**范围查询**场景中的性能就都非常优秀
  + 仅仅看查询效率，有序数组就是最好的数据结构。
  + 更新数据时，若中间插入一条记录，就必须挪动后面所有记录，成本太高。
  + 有序数组索引只适用于**静态存储**引擎。

+ 搜索树
  + 二叉搜索树，**左子节点 < Node < 右子节点**。
  + 平衡二叉树的查询/更新复杂度 O(logN) 。
  + 多叉树，就是每个节点有多个子节点，子节点之间的大小保证从左到右递增。
  + **二叉树搜索效率最高**，但实际上大多数的数据库存储却并不使用二叉树。其原因是，**索引不止存在内存中，还要写到磁盘上**。
  + N 叉树，**降低树高，加快查找时间，以及适配磁盘的访问模式**，被广泛应用在搜索引擎。

### 索引的选择

为了让一个查询尽量少地读磁盘，就必须**让查询过程访问尽量少的数据块**。那么就不应该使用二叉树，而是要**使用“N 叉”树。N 取决于数据块的大小**。

以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 时，就可以存 1200 的 3 次方个值，即 17 亿。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

## InnoDB 的索引模型

**在 InnoDB 中，表是根据主键顺序以索引的形式存放的**，这种存储方式的表称为索引组织表。**使用了 B+树索引模型**，所以数据都是存储在 B+树中的。

![InnoDB 索引组织架构](../../../assets/深入浅出MySQL索引/innoDB_index.png)

在通过 B+树检索时，一般索引树高为 2-4 层，所以最多只需 2-4 次 IO。同时并不是直接找到行，只是找到行所在的页，通过把整个页读入内存，在从内存中查找。范围查询也只需找到数据页，然后遍历其所在的链表即可。

**B 树与 B+树区别**

1. **B+树的磁盘读写代价更低**。B+树的内部没有指向关键字具体信息的指针，其关键字都存储在也节点的链表中，所以其内部节点相对 B 树更小，若把所有关键字存放在同一块盘中，那么盘中所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相应的，IO 读写次数就降低了。
2. **树的查询效率更加稳定**。B+树所有数据都存在于叶子节点，所有关键字查询的路径长度相同，每次数据的查询效率相当。而 B 树可能在非叶子节点就停止查找了，所以查询效率不够稳定。
3. B+树只需要**遍历叶子节点就可以实现整棵树的遍历**。

MongoDB 使用的是 B 树，因为 MongoDB 不是传统的关系型数据库，而是以 Json 格式作为存储的 NoSQL 非关系型数据库，目的就是高性能、高可用、易扩展。摆脱了关系模型，所以**范围查询和遍历查询的需求就没那么强烈了**。

**索引使用要点**

1. B+ 树为了维护索引有序性，在插入新值时需要做必要的维护。中间插入，需要逻辑上挪动后面的数据，空出位置。若后一个数据页已经满了。根据 B+ 树算法，此时需要**申请一个新的数据页，然后挪动部分数据过去，这个过程叫页分裂**。在这种情况下，性能自然会受影响。
2. 除了性能外，**页分裂操作还影响数据页的利用率**。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。
3. 当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低后，会将数据页做合并。合并的过程可以认为是分裂的逆过程。
4. **重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高**，使索引更紧凑、更省空间。
5. 自增主键的插入数据模式，符合递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。从性能和存储空间方面考量，自增主键往往是更合理的选择。
6. 由于每个非主键索引的叶子节点上都是主键的值，如果用业务数据做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，长整型（bigint）则是 8 个字节。
7. **主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小**。
8. 在**只有一个索引**，**索引必须是唯一索引**，情况下适合用业务字段做主键。

### 聚簇索引与辅助索引

1. 主键索引。**叶子节点存的是整行数据**。在 InnoDB 里，主键索引也被称为**聚簇索引**（clustered index）

2. 普通索引。**叶子节点内容是主键的值**。在 InnoDB 里，非主键索引也被称为**辅助索引**，也叫二级索引（secondary index）

两者查询区别：

+ 查询条件是主键，通过主键查询方式，则只需要**搜索 ID 这棵 B+ 树**；
+ 查询条件是非主键但有索引，即普通索引查询方式，则**需要先搜索条件的索引树，得到主键的值，再到主键索引树搜索一次**。这个过程称为**回表**。

基于非主键索引的查询需要多扫描一棵索引树。因此，在应用中应尽量使用主键查询。同时也不建议将较长的字段作为主键索引。

### 覆盖索引

若执行的语句是 ``select ID from T where k between 3 and 5``，这时只需要查 ID 的值，而 ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，无需回表。也就是说，在这个查询里面，**索引 k 已经“覆盖了”查询结果的需求，称为覆盖索引**。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

索引覆盖，创建联合索引，在用这个索引查询时，叶子节点存储了需要查询的所有字段，这样就可以避免回表操作了。

### 最左前缀原则

B+ 树这种索引结构，可以利用**索引的最左前缀，来定位记录**。不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。也叫最左匹配原则。

如 index(a,b,c) 联合索引，则相当于创建了 a 单列索引，(a,b) 联合索引，和 (a,b,c) 联合索引。

联合索引内部就是有序的，可以理解为类似于 order by a,b,c 这样的排序规则。会先根据 a 排序，若 a 相同，再根据 b 排序，依次类推。

**在建立联合索引时，如何安排索引内的字段顺序**

1. 索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，**第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的**。
2. 其次考虑的原则是**空间**。比如市民表的情况，name 字段是比 age 字段大的 ，那就建议创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。
3. 若条件为``where a = 1 and c = 1``，此时也是可以走到 index(a,b,c) 联合索引。
4. 若 ``select a,b,c from t where c = 1``，此时也可以走到该索引，但不满足最左匹配原则，explain 为 index，即**扫描整棵覆盖索引树**。遇到范围查询 (>、<、between、like)，也是如此，会停止匹配。

### 索引下推

MySQL5.6 引入的索引下推优化（index condition pushdown），可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

```sql
select * from t where name = '张三' and age = 10
```

无下推。每个虚线箭头表示回表一次。

![无索引下推](../../../assets/深入浅出MySQL索引/no_index_push_down.png)

有下推。在内部判断了 age 是否等于 10，不等于的直接跳过，只需要回表 2 次。

![符合索引下推](../../../assets/深入浅出MySQL索引/index_push_down.png)

## InnoDB 索引维护

### 查询过程

InnoDB 的**数据是按数据页为单位来读写的，每个数据页默认大小是 16KB**，其中元数据只占大约 128 字节左右（包括文件管理头信息、页面头信息等等），大多数空间都用来存储数据。

当需要读一条记录时，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整页读入内存。

假设执行查询的语句是 ``select id from T where k = 5``。此语句在索引树上查找的过程：

1. 首先 B+树**从树根开始，按层搜索到叶子节点**，也就是图一中右下角的这个数据页；
2. 然后可以认为**数据页内部通过二分法来定位记录**。对于唯一索引，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索；对于普通索引，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。这个不同带来的性能差距微乎其微。

由于引擎是按页读写的，所以当找到 k=5 的记录时，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录” 的操作，就只需要一次指针寻找和一次计算。当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，会稍微复杂一些。但是对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。

### 更新过程

当需要更新一个数据页时，

+ **若数据页在内存中就直接更新**；
+ 若这个数据页还没有在内存中，在不影响数据一致性的前提下，InnoDB 会**将这些更新操作缓存在 change buffer 中**，此时就不需要从磁盘中读入这个数据页了。**在下次查询需要访问这个数据页时，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作**。通过这种方式就能保证这个数据逻辑的正确性。

change buffer 是可以持久化的数据。它在内存中有拷贝，也会被写入到磁盘上。

**将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 purge**。purge 的时机有：

+ 访问这个数据页会触发 purge。
+ 系统有后台线程会定期 purge。
+ 在数据库正常关闭（shutdown）的过程中，也会执行 purge 操作。

显然，若能够**将更新操作先记录在 change buffer，减少读磁盘**，可以明显**提升语句的执行速度**。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够**避免占用内存**，**提高内存利用率**。

### change buffer 的使用

**唯一索引无法使用 change buffer**。对于唯一索引，所有的更新操作都要先判断这个操作**是否违反唯一性约束**，而这必须要将数据页读入内存才能判断。都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

change buffer 用的是 buffer pool 里的内存，因此空间受限。change buffer 的大小，可以通过参数 **innodb_change_buffer_max_size** 来动态设置。这个参数设置为 50 时，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

#### 新增行的处理流程

**1. 这行纪录要更新的目标页已经在内存中**

+ 对于唯一索引来说，找到 ID 所在区间范围内的位置，判断没有冲突，插入这个值，执行结束；
+ 对于普通索引来说，找到索引值所在区间范围内的位置，插入这个值，执行结束。

普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。

**2. 这行纪录要更新的目标页不在内存中**

+ 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，执行结束；
+ 对于普通索引来说，将更新记录在 change buffer，执行结束。

**将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里成本最高的操作之一**。change buffer 因为减少了随机磁盘访问，所以能明显提升更新性能。

#### 使用场景

因为 purge 时才是真正进行数据更新的时刻，而 **change buffer 的主要目的就是将记录的变更动作缓存下来**，所以在一个数据页做 purge 前，**change buffer 记录的变更越多（这个页面上要更新的次数越多），收益就越大**。

+ **写多读少的业务**，页面在写完后马上被访问到的概率比较小，change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
+ 相反，如果一个业务是**写入后马上会做查询**，那么先将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 purge。这样随机**访问 IO **的次数不会减少，反而增加了 change buffer 的维护代价。此时 change buffer 反而起到了副作用。

### 索引选择和实践

普通索引和唯一索引的选择。这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以尽量选择普通索引。

若所有的更新后面，都马上伴随对这个记录的查询，那应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

在实际使用中，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。

在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。

### change buffer 和 redo log

WAL 提升性能的核心机制，也是尽量减少随机读写。

```sql
insert into t(id,k) values(id1,k1),(id2,k2);
```

假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。

如图所示是带 change buffer 的更新状态图。

![change buffer 的更新状态](../../../assets/深入浅出MySQL索引/change_buffer.png)

这条更新语句涉及四个部分：内存、redo log（ib_log_fileX）、数据表空间（t.ibd）、系统表空间（ibdata1）

操作如下：

1. Page 1 在内存中，直接更新内存；
2. Page 2 不在内存中，就在内存的 change buffer 区域记录下“要往 Page 2 插入一行”这个信息。
3. 将上述两个动作记入 redo log 中。步骤 3 和 4。

操作结束，事务就可以完成了。所以，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘（两次操作合在一起写了一次磁盘），而且还是顺序写的。图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

```sql
-- insert 后的查询
select * from t where k in (k1,k2);
```

若读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间 (ibdata1) 和 redo log(ib_log_fileX) 无关了。

![读取内存中的数据页](../../../assets/深入浅出MySQL索引/data_page_in_memory.png)

1. 读 Page 1 时，直接从内存返回。WAL 之后若读数据，不一定要读盘，也不一定要从 redo log 里面把数据更新后才可以返回。图中的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。

2. 读 Page 2 时，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。

可以看到，直到需要读 Page 2 时，这个数据页才会被读入内存。

如果要简单地对比这两个机制在提升更新性能上的收益的话，**redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**

### merge 的执行流程

1. 从磁盘读入数据页到内存（老版本的数据页）;

2. 从 change buffer 里找出这个数据页的 change buffer 记录 （可能有多个），依次应用， 得到新版数据页；
3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。

merge 过程就结束。此时数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。

## 给字符串增加索引

若直接给字符串创建完整的索引，可能会占用较大的空间。

索引选取的越长，占用的磁盘空间就越大，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。

### 前缀索引优劣分析

MySQL 支持前缀索引，可以定义字符串的一部分作为索引。默认若创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。

<!-- more -->

```sql
-- index1 包含整个字符串
alter table User add index index1(email);
-- index2 只取前 6 个字节
alter table User add index index2(email(6));
```

![index1/2 索引](../../../assets/深入浅出MySQL索引/prefix_index.png)

前缀索引**优势是占用空间更小**，但**可能会增加额外的记录扫描次数**。

执行顺序：

1. 索引树上找到 zhangs，找到第一个 ID1；
2. 到主键树上找到主键值为 ID1 的行，判断 email 值是否为 *zhangsan@xxx.com*，不是则丢弃。
3. 取到 index2 上 ID1 下一个，发现仍为 zhangs，取出 ID2，再到主键树取整行，发现是，则记入结果集。
4. 重复上述步骤，直到 index2 上取到值部位 zhangs 时，循环结束。

注意：使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。所以**建索引时，关注的是区分度，区分度越高越好**。因为区分度越高，意味着重复的键值越少。当然，使用前缀索引很可能会损失区分度，所以需要预先设定一个可以接受的损失比例，比如 5%。然后，在返回的 L4~L7 中，找出不小于 L * 95% 的值，假设这里 L6、L7 都满足，就可以选择前缀长度为 6。

```sql
--取不同长度的前缀来看这个值，看适合多少字节的前缀索引
select
  count(distinct left(email,4))as L4,
  count(distinct left(email,5))as L5,
  count(distinct left(email,6))as L6,
  count(distinct left(email,7))as L7,
from User;  
```

**对覆盖索引的影响**

例如上面的 index1 利用覆盖索引，找到结果直接返回了，不需要会主键索引再查一次。而使用 index2 是前缀索引，则需要，前缀索引再长也没用，因为系统不知道前缀索引是否截断了完整信息。即**使用前缀索引就用不上覆盖索引对查询性能的优化了**。

### 其他方式增加索引

+ **使用倒序存储**。数据倒过来再使用前缀索引，主要为了有比较好的区分度（使用 distinct 验证），但不支持范围扫描
+ **使用 hash 字段**。表上再创建一个整数字段，来保存字段的校验码，同时在这个字段上创建索引，缩小索引长度。查询性能稳定，但有额外的存储和计算消耗，不支持范围扫描。只支持等值查询。

### 两者优劣比较

1. 从**占用的额外空间**来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。

2. 在 **CPU 消耗**方面，倒序方式每次写和读时，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 `crc32()` 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。

3. 从**查询效率**上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。

## 选错索引的原因

优化器选择索引，目的是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里，扫描行数是影响执行代价的因素之一。

**扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少**。

但扫描行数并不是唯一的判断标准，优化器还会结合**是否使用临时表**、**是否排序**等因素进行综合判断。

所以选错的原因有，

1. 优化器判断使用主键索引不需要回表操作，所以误认为扫描行数多的但是为主键索引的更快。
2. 优化器判断使用某个索引可以避免排序。

### 判断扫描行数

MySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。

这个统计信息就是索引的“区分度”。**一个索引上不同的值越多，这个索引的区分度就越好**。一个索引上不同的值的个数，称之为“基数”(cardinality)。也就是说，这个基数越大，索引的区分度越好。

可以使用 ``show index from t``  查看一个索引的基数。

### 获取索引的基数

由于一行行统计代价太高，MySQL 通过采样统计来获得索引的基数。所以并不准确。

InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。由于数据表会持续更新，所以，当变更的数据行数超过 1/M 时，会自动触发重新做一次索引统计。``analyze table t`` 可以用来重新统计索引信息。

在 MySQL 中，通过设置参数 ``innodb_stats_persistent`` 来选择两种存储索引统计的方式

+ 设置为 on 时，表示统计信息会持久化存储。此时，默认的 N 是 20，M 是 10。 
+ 设置为 off 时，表示统计信息只存储在内存中。此时，默认的 N 是 8，M 是 16。

除了索引统计，对于具体语句，**优化器还要判断执行这个语句本身要扫描多少行**。explain 里 rows 字段表示预计扫描行数。但其实如果使用索引后，每次从索引上拿到值，都要回主键索引上查出整行数据（回表消耗），这个代价优化器也会算进去。所以**会导致优化器会误认为预计扫描行数多的但扫描的是主键索引的更快，导致选中了非执行时间最优的方式**。

### 索引选择异常和处理

#### 强制走索引

使用 **force index** 强行选择一个索引，为了及时变更，属于没有办法的办法。

MySQL 会根据词法解析的结果分析出可能可以使用的索引作为候选项，然后在候选列表中依次判断每个索引需要扫描多少行。若 force index 指定的索引在候选索引列表中，就**直接选择这个索引**，不再评估其他索引的执行代价。

#### 新建索引

在有些场景下，可以**新建一个更合适的索引**，来提供给优化器做选择，**或删掉误用的索引**。

#### 修改语句

**考虑修改语句，引导 MySQL 使用期望的索引**。

比如：它认为使用某个索引**可以避免排序**（当前的索引本身已经是有序的了，如果选择他的话，不需要再做排序，只需要遍历），所以即使扫描行数多，也判定为代价更小。

此时重写 SQL，让优化器认为不管选哪个索引都需要排序。比如 `order by b limit 1` 改成 `order by b,a limit 1`。因此，扫描行数成了影响决策的主要条件，此时优化器就只会选择扫描行数较少的。**但必须要保证修改前后语义一致**。

## 参考资料

《MySQL 45 讲》