---
title: 并发理论基础
description: 从理论方面分析，并发解决的问题和带来的问题，以及为了保证线程安全的三大特性
toc: true
authors: 
    - WayneShen
tags: 
    - Concurrent
    - Java
    - Notes
categories: 
    - Java
series: []
date: '2020-04-28T22:15:+08:00'
lastmod: '2020-04-28T22:15:20+08:00'
featuredImage: ''
draft: false
---


从理论方面分析，并发解决的问题和带来的问题，以及为了保证线程安全的三大特性。

<!--more-->


## 并发解决的问题

### 资源利用率

现代设备各个模块间处理数据的速度存在差异，CPU数据最快，内存其次，IO设备最慢。

所以为了合理的利用 CPU 的高性能，平衡三者之间的速度差异，计算机体系体系机构、操作系统、编译程序都做出了贡献，主要体现为：

1. CPU增加了缓存，以均衡与内存的速度差异;

2. 操作系统增加了进程、线程，以分时复用CPU，进而均衡 CPU 与 I/O 设备的速度差异; 

3. 编译程序优化指令执行次序，使得缓存能够得到更加合理地利用。


### 公平性

不同用户和程序对于计算机上的资源有着同等的使用权，一种高效的运行方式就是通过时间分片（Time Slicing）使这些用户和程序能共享计算机资源。

### 便利性

通常，计算多个任务时，应编写多个程序，每个程序执行一个任务并在必要时相互通信，比编写一个程序来计算所有任务更容易实现。



## 并发带来的问题

### 安全性问题

所谓 **线程安全** 就是：当多个线程访问某个类时，不管运行环境采用 **何种调度方式** 或者这些进程将如何交替执行，并且 **在主调代码中不需要任何额外的同步或协同**，这个类都能表现出正确的行为（与单线程执行结果一致）。

简单来说，就是程序按照开发者期望的执行。

理论上线程安全的程序，就要避免出现原子性问题、可见性问题和有序性问题。当存在共享数据并且该数据会发生变化，也就是说有多个线程会同时读写同一数据，就需要考虑线程安全性问题。

当多个线程同时访问同一数据，并且至少有一个线程会写这个数据时，如果不采取防护措施，导致并发Bug，出现脏数据或错误数据，叫做数据竞争（Data Race）。

有个概念叫竞态条件（Race Condition）。指的是**程序的执行结果依赖线程执行的顺序**。

### 活跃性问题

活跃性关注的是，某件正确的事最终会发生。当某个操作无法执行下去，就引发了活跃性问题。

典型的活跃性问题有：死锁、活锁、饥饿。

#### 死锁

发生**死锁**后线程会互相等待，而且会一直等待下去，在技术上的表现形式是线程永久地**阻塞**了。

发生死锁的必要条件有：互斥条件、请求和保持条件、不剥夺条件、环路等待条件。

#### 活锁

有时线程虽然没有发生阻塞，但仍然执行不下去，就是**活锁** 。现实的例子就是“两人撞见，并一直相互谦让”。

解决方案很简单，引入随机性。只要在谦让时，尝试等待一个随机的时间。知名的分布式一致性算法Raft，就是用了这个思想。

#### 饥饿

**饥饿**指的是线程因无法访问所需资源而无法执行下去。

若线程优先级不均衡，在CPU繁忙的情况下，优先级低的线程得到执行的机会很小，就可能发生线程饥饿；

持有锁的线程，如果执行的时间过长，也可能导致“饥饿”问题。

解决**饥饿**的方案有三种：

1. 保证资源充足；
2. 公平地分配资源；
3. 避免持有锁的线程长时间执行。

其中方案一和三的适用场景比较有限，因为很多场景下，资源的稀缺性是没办法解决的，持有锁的线程执行的时间也很难缩短。

方案二的适用场景相对更多，所谓公平分配，主要就是使用**公平锁**，也就是先来后到，线程的等待是有顺序的，排在等待队列前面的线程会优先获得资源。

### 性能问题

> 对性能的追求很可能是并发 bug 唯一最大的来源。

在使用锁的过程中，需要格外小心。若**锁**过度使用或使用不当，可能导致串行化的范围过大，就无法发挥多线程的优势了，与并发程序提升性能的初衷背道而驰。

所以要**尽量减少串行**，计算串行对性能的影响，有个阿姆达尔（Amdahl）定律，代表了**处理器并行运算之后效率提升的能力**。公式为：
$$
S=\frac{1}{(1-p)+\frac{p}{n}}
$$
公式里的 n 可以理解为CPU的核数，p 可以理解为并行百分比，那（1-p）就是串行百分比了，假设串行百分比5%。假设CPU的核数（n）无穷大，那加速比S的极限就是20。也就是说，若串行率是5%，那么无论采用什么技术，最高也就只能提高20倍的性能。

![image-20210510101244337](../../../assets/并发理论基础/image-20210510101244337.png)

#### 从方案层面解决性能问题：

##### 减少切换上下文

线程上下文切换需要付出代价，比如：线程的调度需要操控 OS 和 JVM 中共享的数据结构。

##### 使用无锁的算法和数据结构

比如线程本地存储（Thread Local Storage, TLS）、写入时复制（Copy-on-write）、乐观锁等；

Java并发包里面的原子类也是一种无锁的数据结构；

Disruptor则是一个无锁的内存队列，性能都非常好。等等

##### 降低锁竞争

1. 缩小锁的范围（“快进快出”），减少锁持有的时间。

   比如将锁无关的代码移出synchronized块。互斥锁本质上是将并行的程序串行化。

2. 减小锁的粒度，让线程减少调用它的频率。

   分拆锁（lock splitting）、分离锁（lock striping），也就是使用相互独立的锁，守卫多个独立的状态变量，需要注意死锁的可能性。

   **用不同的锁对受保护资源进行精细化管理，能够提升性能，就叫细粒度锁**。

   若多个资源有关联关系的，那么相当于临界区有多个资源，此时锁就需要覆盖所有受保护的资源，或使用共享锁。

   ConcurrentHashMap，它使用了所谓分段锁（分离锁）的技术。

3. 避免热点域

   当每个操作都请求变量时，锁的粒度很难被降低，这是性能和可伸缩性相互牵制的另一方面，通常使用的优化方式有，比如缓存常用的计算结果，会引入热点域，从而限制可伸缩性。

4. 独占锁的替代方式

   提前使用独占锁有助于减轻竞争锁带来的影响，有助于使用更加友好的并发方式进行共享状态的管理。包括有：并发容器、读-写锁、不可变对象、原子变量等。

#### 监测指标

性能方面的度量指标有很多，有三个指标非常重要：吞吐量、延迟和并发量。

**吞吐量**：单位时间内能处理的请求数量。吞吐量越高，性能越好。

**延迟**：从发出请求到收到响应的时间。延迟越小，性能越好。

**并发量**：能同时处理的请求数量，一般来说随着并发量的增加，延迟也会增加。所以延迟一般都是基于并发量来说的。例如并发量是xxx的时候，延迟是xx毫秒。

总的来说，使用多线程主要就是降低延迟，提高吞吐量。



## 线程安全的三大问题

### 原子性

**把一个或多个操作在CPU执行的过程中不被中断的特性称为原子性**。CPU 能保证的原子操作是 CPU 指令级别的，而不是高级语言的操作符。

也就是说，一次或多次操作中，要么所有的操作都执行并不受其他因素干扰而中断，要么所有操作都不执行。

原子性外在表现是不可分割，其本质就是**多个资源间有一致性的要求，操作的中间状态对外不可见**。

所以**解决原子性问题，是要保证中间状态对外不可见**。也就是说，提供了互斥访问，同一时刻只能有一个线程来对其进行操作。

#### 互斥

“**同一时刻只有一个线程执行**”这个条件非常重要，被称为互斥。

若能够保证对共享变量的修改是互斥的，那无论是单核还是多核 CPU，都能保证原子性了。

谈到互斥，一定会想到锁。**把一段需要互斥执行的代码称为临界区**。临界区的代码是操作受保护资源的路径，同时受保护资源和锁之间的关联关系是 N:1 的关系。

#### 线程切换引入的原因

由于IO太慢，早期操作系统增加了多进程，单核CPU可以利用多进程实现同时做多件事。操作系统允许某个进程执行一小段时间，例如50毫秒，过了50毫秒操作系统就会重新选择一个进程来执行（称为“任务切换”），这个50毫秒称为“时间片”。

在一个时间片内，若一个进程进行一个IO操作，例如读个文件，此时该进程可以把自己标记为“休眠状态”并出让CPU的使用权，待文件读进内存，操作系统会把这个休眠的进程唤醒，唤醒后的进程就有机会重新获得CPU的使用权了。让出使用权后，CPU就能处理别的任务，提高了CPU的利用率。

早期操作系统基于进程来调度CPU，不同进程间不共享内存空间，所以进程要做任务切换就要切换内存映射地址，而一个进程创建的所有线程都是共享一个内存空间的，所以线程做任务切换成本就很低。现代的操作系统都基于更轻量的线程来调度，现在提到的“任务切换”都是指“线程切换”。

并发编程基于多线程，自然涉及到任务切换，高级语言中一条语句往往需要多条 CPU 指令，比如 `count += 1`，至少需要三条CPU指令：

1. 指令1：首先，需要把变量 count 从内存加载到 CPU 的寄存器;
2. 指令2：之后，在寄存器中执行 `+1` 操作;
3. 指令3：最后，将结果写入内存（缓存机制导致可能写入的是CPU缓存而不是内存）。

如果能禁用线程切换，就能解决原子性问题，而 OS 做线程切换是依赖 CPU 中断的，单核 CPU 可行，多核 CPU 不可行。

比如，32 位 CPU 上执行 long 型变量的写操作时，long型变量是64位，在32位CPU上执行写操作会被拆分成两次写操作（写高32位和写低32位）。

在单核 CPU 场景下，同一时刻只有一个线程执行，禁止CPU中断，意味着 OS 不会重新调度线程，也就是禁止了线程切换，获得CPU使用权的线程就可以不间断地执行，所以两次写操作一定是：要么都被执行，要么都没有被执行，具有原子性。

#### 解决方案

atomic、synchronized

### 可见性

一个线程对主内存的修改（该线程堆共享变量）可以及时被其他线程观察到。

#### 高速缓存引入

多核时代，每颗 CPU 都有自己的缓存，较难解决 CPU 缓存与内存的数据一致性问题，因为当多个线程在不同的CPU上执行时，这些线程操作的是不同的CPU缓存。

线程交叉执行，共享变量更新后的值没有在工作内存和主存之间及时更新，就会共享变量在线程间不可见。

##### 解决方案

synchronized、volatile

CPU层面解决方案是，总线锁、缓存锁，但会导致性能问题。

### 有序性

一个线程观察其他线程中的指令执行顺序，由于指令重排序的存在，该观察结果一般杂乱无序。

#### 编译优化引入

编译器为了优化性能，提高执行效率，有时会改变程序中语句的先后顺序。编译器和 CPU 会对程序中的代码进行重排序，但只能保证单线程下是正确的。写后读、写后写、读后写，不会进行重排序。

#### 解决方案

happends-before原则、volatile、synchronized、Lock



## 参考资料

《Java并发编程实战》
