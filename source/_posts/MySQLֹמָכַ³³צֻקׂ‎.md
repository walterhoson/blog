---
title: 深入浅出MySQL索引
date: 2020-09-11 23:31:01
tags: [MySQL,note]
description: 分析MySQL中索引数据模型，以及索引的维护...
read_more: 阅读全文
categories: MySQL
toc: true
---

## 索引的常见模型

### 常见索引数据结构：

+ 哈希表
  + 不是有序的，哈希索引做区间查询的速度很慢。
  + 无法利用索引进行排序，也无法实现多列联合索引的最左匹配原则
  + 哈希表这种结构适用于只有等值查询的场景，比如 Memcached 以及其他一些 NoSQL 引擎
  + 还会存在 hash 碰撞的问题

+ 有序数组
  + 有序数组在**等值查询**和**范围查询**场景中的性能就都非常优秀
  + 仅仅看查询效率，有序数组就是最好的数据结构。
  + 更新数据时，若中间插入一条记录，就必须挪动后面所有记录，成本太高。
  + 有序数组索引只适用于**静态存储**引擎

+ 搜索树
  + 二叉搜索树
    + 左子节点 < Node < 右子节点 
  + 平衡二叉树的查询/更新复杂度 O(logN) 
  + 多叉树
    + 多叉树就是每个节点有多个子节点，子节点之间的大小保证从左到右递增
  + 二叉树搜索效率最高，但是实际上大多数的数据库存储却并不使用二叉树。其原因
    是，索引不止存在内存中，还要写到磁盘上。
  + N叉树，降低树高，加快查找时间，以及适配磁盘的访问模式，被广泛应用在搜索引擎

### 索引选择

为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么就不应该使用二叉树，而是要使用“N 叉”树。N 取决于数据块的大小。

以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，17 亿。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。



## InnoDB的索引模型

在 InnoDB 中，表是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。

1. 主键索引。叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为**聚簇索引**（clustered index）

2. 普通索引。叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为**辅助索引**，也叫二级索引（secondary index）


两者查询区别：

+ 查询条件是主键，通过主键查询方式，则只需要搜索 ID 这棵 B+树；
+ 查询条件是非主键但有索引，即普通索引查询方式，则需要先搜索条件的索引树，得到主键的值，再到主键索引树搜索一次。这个过程称为**回表**。

基于非主键索引的查询需要多扫描一棵索引树。因此，在应用中应尽量使用主键查询。



### 索引维护

1. B+ 树为了维护索引有序性，在插入新值的时候需要做必要的维护。中间插入，需要逻辑上挪动后面的数据，空出位置。如果后一个数据页已经满了。根据 B+ 树算法，这时候需要**申请一个新的数据页，然后挪动部分数据过去，这个过程叫页分裂**。在这种情况下，性能自然会受影响。
2. 除了性能外，**页分裂操作还影响数据页的利用率**。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。
3. 当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低后，会将数据页做合并。合并的过程可以认为是分裂的逆过程。
4. **重建索引的过程会创建一个新的索引，把数据按顺序插入，这样页面的利用率最高**，也就是索引更紧凑、更省空间。
5. 自增主键的插入数据模式，符合递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。从性能和存储空间方面考量，自增主键往往是更合理的选择。
6. 由于每个非主键索引的叶子节点上都是主键的值，如果用业务数据做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，长整型（bigint）则是 8 个字节。
7. **主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小**。
8. 在**只有一个索引**，**索引必须是唯一索引**，情况下适合用业务字段做主键



### 覆盖索引

若执行的语句是 ``select ID from T where k between 3 and 5``，这时只需要查 ID 的值，而ID 的值已经在 k 索引树上了，因此可以直接提供查询结果，不需要回表。也就是说，在这个查询里面，**索引 k 已经“覆盖了”查询结果的需求，称为覆盖索引**。

**由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。**

索引覆盖，创建联合索引，在用这个索引查询时，叶子节点存储了需要查询的所有字段，这样就可以避免回表操作了。



### 最左前缀原则

B+ 树这种索引结构，可以利用索引的**最左前缀**，来定位记录。不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。也叫最左匹配原则。

如 index(a,b,c) 联合索引，则相当于创建了 a 单列索引，(a,b) 联合索引，和 (a,b,c) 联合索引。

联合索引内部就是有序的，可以理解为类似于 order by a,b,c 这样的排序规则。会先根据 a 排序，若 a 相同，再根据 b 排序，依次类推。

**在建立联合索引的时候，如何安排索引内的字段顺序**

1. 索引的复用能力。因为可以支持最左前缀，所以当已经有了 (a,b) 这个联合索引后，一般就不需要单独在 a 上建立索引了。因此，**第一原则是，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要优先考虑采用的**。
2. 其次考虑的原则是**空间**。比如市民表的情况，name 字段是比 age 字段大的 ，那就建议创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。
3. 若条件为``where a = 1 and c = 1``，此时也是可以走到index(a,b,c) 联合索引。
4. 若 ``select a,b,c from t where c = 1``，此时也可以走到该索引，但不满足最左匹配原则，explain为index，即扫描整颗覆盖索引树。遇到范围查询(>、<、between、like)，也是如此，会停止匹配。



### 索引下推

MySQL5.6 引入的索引下推优化（index condition pushdown），可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

无下推。每个虚线箭头表示回表一次。

![无索引下推](image-20200911175237452.png)

``select * from t where name = '张三' and age = 10``

有下推。在内部判断了age是否等于10，不等于的直接跳过，只需要回表2次。

![符合索引下推](image-20200911175308566.png)





## 普通索引和唯一索引

不建议将较长的字段作为主键索引。

InnoDB 索引组织架构

![InnoDB 索引组织架构](image-20200921114940727.png)



### 查询过程

假设执行查询的语句是  ``select id from T where k=5``。此语句在索引树上查找的过程：

1. 先通过 B+ 树从树根开始，按层搜索到叶子节点，也就是图中右下角的这个数据页

2. 然后可以认为数据页内部通过二分法来定位记录。

   + 对于普通索引来说，查找到满足条件的第一个记录 (5,500) 后，需要查找下一个记录，直到碰到第一个不满足 k=5 条件的记录。

   + 对于唯一索引来说，由于索引定义了唯一性，查找到第一个满足条件的记录后，就会停止继续检索。

   这个不同带来的性能差距微乎其微。

   InnoDB 的**数据是按数据页为单位来读写的**。当需要读一条记录的时候，并不是将这个记录本身从磁盘读出来，而是以页为单位，将其整页读入内存。在 InnoDB 中，**每个数据页的大小默认是16KB**。

因为引擎是按页读写的，所以，当找到 k=5 的记录的时候，它所在的数据页就都在内存里了。那么，对于普通索引来说，要多做的那一次“查找和判断下一条记录” 的操作，就只需要一次指针寻找和一次计算。当然，如果 k=5 这个记录刚好是这个数据页的最后一个记录，那么要取下一个记录，必须读取下一个数据页，这个操作会稍微复杂一些。但是对于整型字段，一个数据页可以放近千个 key，因此出现这种情况的概率会很低。所以，计算平均性能差异时，仍可以认为这个操作成本对于现在的 CPU 来说可以忽略不计。



### 更新过程

当需要更新一个数据页时

+ 如果数据页在内存中就直接更新
+ 如果这个数据页还没有在内存中，在不影响数据一致性的前提下，InooDB 会**将这些更新操作缓存在 change buffer 中**，此时就不需要从磁盘中读入这个数据页了。**在下次查询需要访问这个数据页时，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作**。通过这种方式就能保证这个数据逻辑的正确性。

change buffer 是可以持久化的数据。它在内存中有拷贝，也会被写入到磁盘上。

**将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 purge**。

+ 访问这个数据页会触发 purge。
+ 系统有后台线程会定期 purge。
+ 在数据库正常关闭（shutdown）的过程中，也会执行 purge 操作。

显然，如果能够**将更新操作先记录在 change buffer，减少读磁盘**，可以明显**提升语句的执行速度**。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够**避免占用内存**，**提高内存利用率**。



### 使用 change Buffer 的条件

**唯一索引无法使用**。对于唯一索引，所有的更新操作都要先判断这个操作**是否违反唯一性约束**，而这必须要将数据页读入内存才能判断。都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 **innodb_change_buffer_max_size**  来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。

#### 插入新纪录的 InnoDB 处理流程

##### 这行纪录要更新的目标页已经在内存中

+ 对于唯一索引来说，找到 ID 所在区间范围内的位置，判断没有冲突，插入这个值，执行结束;
+ 对于普通索引来说，找到索引值所在区间范围内的位置，插入这个值，执行结束。

普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。

##### 这行纪录要更新的目标页不在内存中

+ 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束;
+ 对于普通索引来说，将更新记录在 change buffer，语句执行结束。

**将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里成本最高的操作之一**。change buffer 因为减少了随机磁盘访问，所以能明显提升更新性能。



### change buffer 的使用场景

因为 purge 时才是真正进行数据更新的时刻，而 **change buffer 的主要目的就是将记录的变更动作缓存下来**，所以在一个数据页做 purge 前，**change buffer 记录的变更越多(这个页面上要更新的次数越多)，收益就越大**。

+ **写多读少的业务**，页面在写完以后马上被访问到的概率比较小，change buffer 的使用效果最好。这种业务模型常见的就是账单类、日志类的系统。
+ 相反，如果一个业务的是**写入后马上会做查询**，那么先将更新先记录在 change buffer，但之后由于马上要访问这个数据页，会立即触发 purge。这样随机 **访问 IO** 的次数不会减少，反而增加了 change buffer 的维护代价。此时change buffer 反而起到了副作用。



### 索引选择和实践

普通索引和唯一索引的选择。这两类索引在查询能力上是没差别的，主要考虑的是对更新性能的影响。所以尽量选择普通索引。

若所有的更新后面，都马上伴随对这个记录的查询，那应该关闭 change buffer。而在其他情况下，change buffer 都能提升更新性能。

在实际使用中，普通索引和 change buffer 的配合使用，对于数据量大的表的更新优化还是很明显的。

在使用机械硬盘时，change buffer 这个机制的收效是非常显著的。所以，当有一个类似“历史数据”的库，并且出于成本考虑用的是机械硬盘时，那应该特别关注这些表里的索引，尽量使用普通索引，然后把 change buffer 尽量开大，以确保这个“历史数据”表的数据写入速度。



### change buffer 和 redo log

WAL 提升性能的核心机制，也是尽量减少随机读写。

```sql
insert into t(id,k) values(id1,k1),(id2,k2);
```

假设当前 k 索引树的状态，查找到位置后，k1 所在的数据页在内存 (InnoDB buffer pool) 中，k2 所在的数据页不在内存中。如图所示是带 change buffer 的更新状态图。

![change buffer的更新状态](image-20200921224244596.png)

这条更新语句涉及四个部分：内存、redo log（ib_log_fileX）、数据表空间（t.ibd）、系统表空间（ibdata1）

操作如下：

1. Page 1 在内存中，直接更新内存;
2. Page 2 没有在内存中，就在内存的 change buffer 区域记录下“要往 Page 2 插入一 行”这个信息
3. 将上述两个动作记入 redo log 中。步骤 3 和 4。

操作结束，事务就可以完成了。所以，执行这条更新语句的成本很低，就是写了两处内存，然后写了一处磁盘(两次操作合在一起写了一次磁盘)，而且还是顺序写的。图中的两个虚线箭头，是后台操作，不影响更新的响应时间。

```sql
-- insert后的查询
select * from t where k in (k1,k2);
```

若读语句发生在更新语句后不久，内存中的数据都还在，那么此时的这两个读操作就与系统表空间(ibdata1)和 redo log(ib_log_fileX)无关了。所以在图中就没画出这两部分。

![读取内存中的数据页](image-20200921225242406.png)

1. 读 Page 1 时，直接从内存返回。WAL之后如果读数据，不一定要读盘，也不一定要从 redo log 里面把数据更新以后才可以返回。图中的这个状态，虽然磁盘上还是之前的数据，但是这里直接从内存返回结果，结果是正确的。

2. 读 Page 2 时，需要把 Page 2 从磁盘读入内存中，然后应用 change buffer 里面的操作日志，生成一个正确的版本并返回结果。

可以看到，直到需要读 Page 2 的时候，这个数据页才会被读入内存。

如果要简单地对比这两个机制在提升更新性能上的收益的话，**redo log 主要节省的是随机写磁盘的 IO 消耗(转成顺序写)，而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。**



### merge 的执行流程是这样的:

1. 从磁盘读入数据页到内存(老版本的数据页);

2. 从 change buffer 里找出这个数据页的 change buffer 记录 (可能有多个)，依次应用， 得到新版数据页;

3. 写 redo log。这个 redo log 包含了数据的变更和 change buffer 的变更。

merge 过程就结束。此时数据页和内存中 change buffer 对应的磁盘位置都还没有修改，属于脏页，之后各自刷回自己的物理数据，就是另外一个过程了。